---
title: "Homework 6"
output: word_document
---
# Problem 9.1

```{r}
library(caret)
library(gains)
#install.packages("randomForest")
library(randomForest)
#install.packages("rpart.plot")
library(rpart.plot)
library(rpart)
ebay.df <- read.csv("eBayAuctions.csv", head= TRUE, sep = ',', stringsAsFactors=FALSE)
ebay.df$endDay <- as.factor(ebay.df$endDay)
ebay.df$Category <- as.factor(ebay.df$Category)
ebay.df$currency <- as.factor(ebay.df$currency)

```


Converting the data into categorical and partitioning into test and train:


```{r}
#Converting Duration to categorical variable for the following intervals (A:0-1, B:1-3, C:3-5, D:5-7, E:7-10), 
ebay.df$Duration <- cut(ebay.df$Duration, breaks = c(0,1,3,5,7,10), labels = c("A", "B", "C", "D", "E"))

#Partioning Data into Training and Validation Sets
set.seed(111)
train.index <- sample(c(1:dim(ebay.df)[1]), dim(ebay.df)[1]*0.6)
train.df <- ebay.df[train.index, ]
valid.df <- ebay.df[-train.index, ]


```


```{r}
#a classification trees

default.ct <- rpart( Competitive. ~ ., data = train.df, method = "class", control = rpart.control(maxdepth = 7, minbucket = 50))
prp(default.ct, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)

```
This is a classification tree with max depth 7 and min bucket = 50 after pruning

```{r}

#full classification tree for the auction data using the training set (1183 records)
deeper.ct <- rpart(Competitive. ~ ., data = train.df, method = "class", cp = 0, minsplit = 1)
length(deeper.ct$frame$var[deeper.ct$frame$var == "<leaf>"])

#Confusion matrices and accuracy for the classification trees
default.ct.point.pred.train <- predict(default.ct,train.df,type = "class")
default.ct.point.pred.valid <- predict(default.ct,valid.df,type = "class")
library(caret)
#confusionMatrix(default.ct.point.pred.train, train.df$Competitive.)
#confusionMatrix(default.ct.point.pred.valid, valid.df$Competitive.)

# Complexity parameter (CP) values and tree errors
cv.ct <- rpart(Competitive. ~ ., data = train.df, method = "class",
               cp = 0.00001, minsplit = 5, xval = 5, control = rpart.control(maxdepth = 7, minbucket = 50))
printcp(cv.ct)

#Pruned classification tree using CP that with lowest error
pruned.ct <- prune(cv.ct, cp = cv.ct$cptable[which.min(cv.ct$cptable[,"xerror"]),"CP"])
length(pruned.ct$frame$var[pruned.ct$frame$var == "<leaf>"])
prp(pruned.ct, type = 1, extra = 1, split.font = 1, varlen = -10)
```

Plot for determining variable importance to reduce the number of predictors.

```{r}

#Variable importance is determined by a plot from Random forest
library(randomForest)
rf <- randomForest(as.factor(Competitive.) ~ ., data = train.df[,3:8], ntree = 500,
                   mtry = 4, nodesize = 5, importance = TRUE)
varImpPlot(rf, type = 1)

```

From the plot we can infer that OpenPrice is the variable we would choose because it gives the highest mean decrease in Accuracy



b) This is not a practical model for predicting the outcome of a new auction since, there is no way to determine the close price of the auction at the start of the auction.

c) The interesting information in these rules is the seller rating. The rules indicate that the competitive auctions are generally generated by the less experienced sellers having high open and close prices. 
The uninteresting information that these rules provide is that the auctions with low close prices, relative to open prices tend to be non-competitive. This is obvious since a single bid is likely to lead to a low close price.


```{r}
rf.pred <- predict(rf, valid.df)
table(rf.pred, valid.df$Competitive.)

#b

pruned.ct.point.pred.valid <- predict(pruned.ct, valid.df, type = "class")
table(pruned.ct.point.pred.valid, valid.df$Competitive.)

#d

#Table of complexity parameter (CP) values and associated tree errors
cv.ct.new <- rpart(Competitive. ~ OpenPrice + ClosePrice, data = train.df, method = "class",
                   cp = 0.00001, minsplit = 5, xval = 5, control = rpart.control(maxdepth = 7, minbucket = 50))
printcp(cv.ct.new)

#Pruned classification tree for the auction data using CP that yielded lowest error
pruned.ct.new <- prune(cv.ct.new, cp = cv.ct.new$cptable[which.min(cv.ct.new$cptable[,"xerror"]),"CP"])
length(pruned.ct.new$frame$var[pruned.ct$frame$var == "<leaf>"])
prp(pruned.ct.new, type = 1, extra = 1, split.font = 1, varlen = -10)
```




```{r}
#e Scattor plot for the resulting tree

ggplot(ebay.df, aes(x=ebay.df$ClosePrice, y=ebay.df$OpenPrice, color=ebay.df$Competitive.)) +
  geom_point(shape=19) + xlim(0,100) + ylim(0, 40) +
         geom_segment(aes(x=0,xend=Inf,y=3.6,yend=3.6)) + 
         geom_segment(aes(x=3.6,xend=3.6,y=0,yend=3.6)) + 
         geom_segment(aes(x=10,xend=10,y=3.6,yend=Inf)) +
         geom_segment(aes(x=10,xend=Inf,y=11,yend=11)) + 
         geom_segment(aes(x=0,xend=3.6,y=0.94,yend=0.94)) + 
         geom_segment(aes(x=40,xend=40,y=11,yend=Inf)) +
         geom_segment(aes(x=0,xend=Inf,y=0,yend=0)) +
         geom_segment(aes(x=0,xend=0,y=0,yend=Inf))
```
The above scatterplot represents an enlarged view of the pruned classification tree. The splitting does seem reasonable with respect to the meaning of the two predictors. No, it doesn't do a good job separating the two classes as all the trees have a large number of impurities.

```{r}


#f

#Confusion Matrix
pruned.ct.point.pred.valid.new <- predict(pruned.ct.new, valid.df, type = "class")
table(pruned.ct.point.pred.valid.new, valid.df$Competitive.)
library(gains)
gain <- gains(valid.df$Competitive., as.numeric(pruned.ct.point.pred.valid.new), groups=10)
#Lift Chart
plot(c(0,gain$cume.pct.of.total*sum(valid.df$Competitive.))~c(0,gain$cume.obs), xlab="number of cases", ylab="Cumulative values", main="", type="l")
plot.new()
#lines(c(0,sum(valid.df$Competitive.))~c(0, dim(valid.df)[1]), lty=2)


```

From Confusion Matrix, we can see that Accuracy of the model is 88%. This means that for a given set of 100 test records this predictive model would correctly classify 88 records.
The area under lift chart also indicates that how much better the model performs than the naïve rule. The above lift chart signifies good model performance


g)
From the tree, we can infer that the opening price is a crucial factor controlled by the seller that influences the competitiveness of the auction. Lower opening price could attract more bidders. Therefore, we recommend that if the opening price is less than $1.23, then it will lead to a competitive auction. The seller strategy should be, setting the opening price to a minimum, as that would most likely to lead to a competitive auction.
# Problem 9.2

```{r}
#install.packages("rattle")
library(rpart)
library(rpart.plot)
library(rattle)

delay <- read.csv("FlightDelays.csv")
unique(delay$DAY_WEEK, incomparables = FALSE)
delay$DAY_WEEK <- as.factor(delay$DAY_WEEK)

#table for ( cut(delay$CRS_DEP_TIME, b = 8))
delay$CRS_DEP_TIME <- as.numeric(delay$CRS_DEP_TIME)
delay$CRS_DEP_TIME<- cut(delay$CRS_DEP_TIME, b = 8, dig.lab = 5)
set.seed(1)
train.index <- sample(c(1:dim(delay)[1]), dim(delay)[1]*0.6)   
train1.df <- delay[train.index, ] 
valid1.df <- delay[-train.index, ]
train.df1 <- subset(train1.df, select = -c(DEP_TIME, TAIL_NUM))
```

a) Fitting a classification tree:
```{r}

#classification tree 
default.ct <- rpart(Flight.Status ~ ., data = train.df1, method = "class") 
prp(default.ct, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10) 

#setting the smallest value for the complexity parameter. 
cv.ct <- rpart(Flight.Status ~ ., data = train.df1, method = "class", cp = 0.001, xval = 5) 

```
Plotting pruned tree:
```{r}
# prune by lower cp 
pruned.ct <- prune(cv.ct,cp=cv.ct$cptable[which.min(cv.ct$cptable[,"xerror"]),"CP"]) 
length(pruned.ct$frame$var[pruned.ct$frame$var == "<leaf>"]) 
#plot pruned tree 
prp(pruned.ct, type = 0, extra = 1, split.font = 1, varlen = -10)


```

Pruned decision tree gives following rules: 
Rule1:
If flight date is not one of 01/04, 01/05, 1/15, 1/16, 1/18, 1/25, 1/26, 1/27, 1/28 then the flight will be on time. 

Rule2. If flight date is one of 01/04, 01/05, 1/15, 1/16, 1/18, 1/25, 1/26, 1/27, 1/28 and If the carrier is not one of CO, DH, MQ, RU, UA then it will be on time.




b) we would not be able to make the decision using this tree because in the pruned tree, there is no information about origin and destination. 
We would need information about Flight date, carrier flight date.
Yes, this information is available in practice. 
Tail num Information is redundant


```{r}
#c)

train.df2 <- subset(train1.df, select = -c(Weather,DEP_TIME))
# setting the smallest value for the complexity parameter. 
cv.ct1 <- rpart(Flight.Status ~ ., data = train.df2, method = "class", cp = 0.001, xval = 5) 
#full tree
prp(cv.ct1, type = 0, extra = 1, split.font = 1, varlen = -10)

```


```{r}

# pruned tree as per lower cp 
pruned.ct1 <- prune(cv.ct1,cp=cv.ct1$cptable[which.min(cv.ct1$cptable[,"xerror"]),"CP"]) 
default.ct$variable.importance
length(pruned.ct1$frame$var[pruned.ct1$frame$var == "<leaf>"]) 
prp(pruned.ct1, type = 0, extra = 1, split.font = 1, varlen = -10) 

```
As seen in result, pruned tree contains only one terminal node. It classifies 261 flights as on time and 1059 flights as delayed. Essentially, it gives the probability of classification of a flight as being on time

```{r}
printcp(cv.ct1)
```
ii.
This rule is equivalent to classification based on probabilities. It signifies that 19.77273% times flights will be on time and otherwise be late

iii. 
Important predictors are TAIL_NUM, FL_DATE, CRS_DEP_TIME. Their importance is shown below.


```{r}
cv.ct1$variable.importance
```

iv. Technically pruned tree contains a single node because, during pruning various control parameters are applied to the original tree. Any split, that does not decrease the overall lack of fit by a factor of cp, is not carried out. Therefore, the pruned tree results in a single node 

v. 
The Classification result obtained from top levels of unpruned tree on
a previously unseen dataset result in a higher classification error as is a high possibility of overfitting data for unpruned tree. In case of the pruned tree the possibility of overfitting is lower. This is the disadvantage of using the top levels of the unpruned tree as opposed to the pruned tree.

vi. Possible reasons for the classification trees failure to fit a good predictive model are:
a. When decision tree is overly complex with a substantial number of predictor variables, it overfits data which result in poor prediction or classification of previously unseen data.
b. When decision tree is very large, with a lot of branches, there is a high possibility that it overfits training data resulting in poor predictive performance on new data.

# Problem 9.3

```{r}
data <- read.csv("ToyotaCorolla.csv")
```

```{r}
library(dummies)
library(rpart.plot)
str(data)
data <- cbind(data, dummy(data$Fuel_Type, sep="_Fuel_"))
data <- cbind(data, dummy(data$Color,sep="_Color_"))
data <- data[,-c(1,2,8,11)]
data <- data[,-c(36,40)]
```

```{r}
set.seed(1234)
ind <- sample(2, nrow(data), replace = T, prob = c(0.6,0.4))
train <- data[ind==1,]
valid <- data[ind==2,]

```

```{r}
data_train <- train[c(1,2,5,6,8,10,13,15,17,21,22,24,26,30,35,36:38)]
model <- rpart(Price ~.,data=data_train, control = rpart.control(minbucket = 1))
cp <- model$cptable[which.min(model$cptable[, "xerror"]), "CP"]
pruned <- prune(model, cp =cp)
pruned
```
```{r}
summary(pruned)
```
AGE_08_04, Automatic_airco, KM, Quarterly_Tax are the four most important car specifications for predicting car price.
```{r}
prp(pruned, type =1, extra= 1, split.font=1, varlen=-10)
```
2)
```{r}
Rmse <- function(error)
{
sqrt(mean(error^2))
}
data_valid <- valid[c(1,2,5,6,8,10,13,15,17,21,22,24,26,30,35,36:38)]
trainpred <- predict(pruned, train)
validpred <- predict(pruned, valid)

```

```{r}
trainerror1 <- trainpred-data_train$Price
Rmse(trainerror1)
validerror1 <- validpred-data_valid$Price
Rmse(validerror1)

boxplot(trainerror1)
boxplot(validerror1)


```
It can be seen that performance of trainiing set is better than the validation set. But both of the sets are having some really bad predictions which turns out to be the outliers in the error which ultimately leads to higher RMS error.

To achieve the predictions in the training set which are not eqaul to their actual values by pruning the tree for least cross validation error.

Error for full tree is higher than in best pruned tree.
```{r}
data1 <- data[c(1,2,5,6,8,10,13,15,17,21,22,24,26,30,35,36:38)]

data1_price <- cut(data1$Price, 20, include.lowest = TRUE, labels = 1:20)
data2 <- cbind(data1_price, data1[-1])
set.seed(1234)
ind <- sample(2, nrow(data2), replace = T, prob = c(0.6,0.4))
train2 <- data2[ind==1,]
valid2 <- data2[ind==2,]
model2 <- rpart(data1_price ~.,data=train2, control = rpart.control(minbucket = 1))
cp2 <- model2$cptable[which.min(model2$cptable[, "xerror"]), "CP"]
pruned2 <- prune(model2, cp =cp2)
prp(pruned2, type =1, extra= 1, split.font=1, varlen=-10)
```

```{r}
new <- data.frame(Age_08_04=77,KM=117000,HP=110,Automatic=0, Doors=5, Quarterly_Tax=100, Mfr_Guarantee=0, Guarantee_Period=3, Airco=1, Automatic_airco=0, CD_Player=0, Powered_Windows=0,Sport_Model=0,Tow_Bar=1,data_Fuel_Diesel=0,data_Fuel_Petrol=1,data_Color_Beige=0)
new_predict_CT <- predict(pruned2, newdata = new, type = 'class')
new_predict_RT <- predict(pruned, newdata = new)
new_predict_CT
new_predict_RT
```
Predicted price for the new record is $ 7860.465 using RT where as 3rd bin as per the CT.

Prediction using RT gives exact value when the response is of numerical type. To get a range you need to convert the response variable into categorical by binning the data to get a range of predicted response.
