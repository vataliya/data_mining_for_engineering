---
title: "Homework 5"
output: word_document
---

Problem 7.1:

Reading the data
```{r}
install.packages("FNN")
library(dummies)
library(FNN)
library(lattice)
library(caret)
bankdata <- read.csv("UniversalBank.csv")
str(bankdata)
head(bankdata)
bankdata <- cbind(bankdata,dummy(bankdata$Education,sep = "_"))
str(bankdata)
bankdata <- bankdata[,-8]
names(bankdata) <-c("ID","Age","Experience","Income","ZIP.Code","Family","CCAvg","Mortgage","Personal.Loan","Securities.Account","CD.Account","Online","CreditCard","Education_1","Education_2","Education_3")
str(bankdata)
```
Partisioning of the data into training and test data
```{r}
set.seed(234)
ind <- sample(2, nrow(bankdata), replace = T,prob = c(0.6,0.4))
train <- bankdata[ind==1,]
test <- bankdata[ind==2,]
head(train)

```
Normalization of the data
```{r}
norm.values <- preProcess(train[,-c(1,5,9,14,15,16)], method = c("center","scale"))
train[,-c(1,5,9,14,15,16)] <- predict(norm.values,train[,-c(1,5,9,14,15,16)])
test[,-c(1,5,9,14,15,16)] <- predict(norm.values,test[,-c(1,5,9,14,15,16)])
head(test)
```
Model Formation
```{r}
nn <- knn(train = train[,-c(1,5,9)], test = test[,-c(1,5,9)], cl =train[,9], k=1)
summary(nn)
data.frame(test$Personal.Loan,nn)[1:10,]
new.data <- c(40,10,84,2,2,0,0,0,1,1,0,1,0)
nn1 <- knn(train = train[,-c(1,5,9)], test = new.data, cl =train[,9], k=1)
nn1
```
The given customer would accept the loan.
```{r}
confusionMatrix(nn, as.factor(test[,9]))

```
```{r}
# initialize a data frame with two columns: k, and accuracy.
acc <- data.frame(k = seq(1, 15, 1), Accuracy = rep(0, 15))
# compute knn for different k on validation.

for(i in 1:15) {
nn2 <- knn(train = train[,-c(1,5,9)], test = test[,-c(1,5,9)], cl =train[,9], k=i)
acc[i,2] <- confusionMatrix(nn2, as.factor(test[,9]))$overall[1]
                            
}
acc
```
K=5 is the best value of k
```{r}
nn5 <- knn(train = train[,-c(1,5,9)], test = test[,-c(1,5,9)], cl =train[,9], k=5)
confusionMatrix(nn, as.factor(test[,9]))

```
Classification of New Customer
```{r}
nn5_1 <- knn(train = train[,-c(1,5,9)], test = new.data, cl =train[,9], k=5)
nn5_1
```
New Customer will accept the loan as per the model.
```{r}
set.seed(2244)
ind1 <- sample(3, nrow(bankdata), replace = T,prob = c(0.5,0.3,0.2))
train_new <- bankdata[ind1==1,]
valid_new <- bankdata[ind1==2,]
test_new <- bankdata[ind1==3,]
norm.values <- preProcess(train[,-c(1,5,9,14,15,16)], method = c("center","scale"))
train_new[,-c(1,5,9,14,15,16)] <- predict(norm.values,train_new[,-c(1,5,9,14,15,16)])
valid_new[,-c(1,5,9,14,15,16)] <- predict(norm.values,valid_new[,-c(1,5,9,14,15,16)])
test_new[,-c(1,5,9,14,15,16)] <- predict(norm.values,test_new[,-c(1,5,9,14,15,16)])
nn_new1 <- knn(train = train_new[,-c(1,5,9)], test = test_new[,-c(1,5,9)], cl =train_new[,9], k=5)
nn_new2 <- knn(train = train_new[,-c(1,5,9)], test = valid_new[,-c(1,5,9)], cl =train_new[,9], k=5)
confusionMatrix(nn_new1, as.factor(test_new[,9]))
confusionMatrix(nn_new2, as.factor(valid_new[,9]))

```
#####

Problem 7.2:

```{r}
library(class)
library(caret)

data <- read.csv("BostonHousing.csv")


str(data)
data <- data[,-14]
```
Data Partition
```{r}
set.seed(256)
ind <- sample(2, nrow(data), replace = T,prob = c(0.6,0.4))
train <- data[ind==1,]
test <- data[ind==2,]
```


```{r}
norm.values <- preProcess(train[,-13], method = c("center","scale"))
train[,-13] <- predict(norm.values,train[,-13])
test[,-13] <- predict(norm.values,test[,-13])
head(train)
```

KNN Model
```{r}
# initialize a data frame with two columns: k, and accuracy.
acc <- data.frame(k = seq(1, 5, 1), RMSE = rep(0, 5))
# compute knn for different k on validation.
for(i in 1:5){
model <- knn(train = train[,-13],test = test[,-13],cl=train[,13], k=i)
model
a <- as.numeric(paste(model))
data1 <- as.data.frame(cbind(a,test[,13]))
data1
acc[i,2] <- RMSE(a,test[,13])
}
acc
```
Model Performance
```{r}
new <- c(0.2,0,7,0,0.538,6,62, 4.7, 4,307,21,10)
newmodel <- knn(train = train[,-13],test = new ,cl=train[,13], k=1)
newmodel
```

```{r}
knn <- knn(train = train[,-13],test = train[,-13],cl=train[,13], k=1)
b <- as.numeric(paste(knn))
RMSE(b, train[,13])
```

#####

Problem 8.1:


```{r}
library(dummies)
library(FNN)
library(lattice)
library(caret)
bankdata <- read.csv("UniversalBank.csv")
str(bankdata)
head(bankdata)
bankdata <- cbind(bankdata,dummy(bankdata$Education,sep = "_"))
bankdata <- bankdata[,-8]
names(bankdata) <-c("ID","Age","Experience","Income","ZIP.Code","Family","CCAvg","Mortgage","Personal.Loan","Securities.Account","CD.Account","Online","CreditCard","Education_1","Education_2","Education_3")

```

```{r}
set.seed(234)
ind <- sample(2, nrow(bankdata), replace = T,prob = c(0.6,0.4))
train <- bankdata[ind==1,c(9,12,13)]
test <- bankdata[ind==2,c(9,12,13)]
```

```{r}
install.packages("reshape")
library(reshape)
train1 <- melt(train, id.vars = c('Online','CreditCard'), measure.vars = 'Personal.Loan', variable_name =c('Output'))
head(train1)
q1 <- cast(train1, Online~CreditCard, sum) 
q1

b_1 <- q1[2,3]/(q1[1,2]+q1[1,3]+q1[2,2]+q1[2,3])
b_1
```
Probability that the given customer will accept the loan is 0.1672
```{r}
a1 <- table(train$Personal.Loan,train$Online)
a2 <- table(train$Personal.Loan, train$CreditCard)
a3 <- table(train$Personal.Loan)
a1
a2
a3
d_1 <- a2[2,2]/(a2[2,1]+a2[2,2])
d_2 <- a1[2,2]/(a1[2,1]+a1[2,2])
d_3 <- a3[2]/(a3[1]+a3[2])
d_4 <- a2[1,2]/(a2[1,1]+a2[1,2])
d_5 <- a1[1,2]/(a1[1,1]+a1[1,2])
d_6 <- 1- d_3

d_1
d_2
  d_3
d_4
d_5
d_6
```

```{r}
Num <- d_1*d_2*d_3
den <-d_4*d_5*d_6
NBP <- Num/(Num+den)
NBP
```

```{r}
b_1
```

```{r}
library(e1071)
model <- naiveBayes(train$Personal.Loan~train$Online+train$CreditCard, data = train)
model
```

#####

Problem 8.2:

Loading dataset

```{r}
library(readxl)
Accidents<- read_excel("Accidents.xlsx", sheet = 5)
Accidents$Injury <- as.factor(ifelse(Accidents$MAX_SEV_IR < 1, "NO", "YES"))
table(Accidents$Injury)


```
a) 
```{r}
ProbYES = sum(Accidents$Injury == "YES")/nrow(Accidents)
ProbNO = sum(Accidents$Injury == "NO")/nrow(Accidents)
ProbYES #probability of injury
ProbNO #probability of no injury

```
Therefore, if no further information is available, it should be assumed that injury has occured.

b) 
```{r}

subauto <-Accidents[1:12,c("Injury", "WEATHER_R", "TRAF_CON_R")]
```
```{r}
table(subauto)
```


Exact Bayes conditional probabilities for six conditions:

P(Injury = YES | WEATHER_R = 1, TRAF_CON_R = 0) = 2/3 = 0.66
P(Injury = YES | WEATHER_R = 1, TRAF_CON_R = 1) = 0
P(Injury = YES | WEATHER_R = 1, TRAF_CON_R = 2) = 0
P(Injury = YES | WEATHER_R = 2, TRAF_CON_R = 0) = 1/3 = 0.33
P(Injury = YES | WEATHER_R = 2, TRAF_CON_R = 1) = 0
P(Injury = YES | WEATHER_R = 2, TRAF_CON_R = 2) = 0

Classify the 12 accidents using these probabilities and a cutoff of 0.5:

From above, recors with WEATHER_R = 1, TRAF_CON_R = 0 classify as having an injury with that cutoff.

iv)
The prob that injury="yes" when traffic=1 and weather=1 is 0 since we find no such recoed in our
working dataset.
Therefore,
P(injury="no"|w=1,t=1)=1
P(injury="yes"|w=1,t=1)=0

(v)
```{r}
subauto
```
```{r}
table(subauto$WEATHER_R, subauto$TRAF_CON_R, subauto$Injury)
```
```{r}
modelNB1 <- naiveBayes(Injury ~ WEATHER_R + TRAF_CON_R, data = subauto)
class(modelNB1)
```
```{r}
modelNB1_predict <- predict(modelNB1, subauto)
table(modelNB1_predict)

```

c)

Partitioning data:

```{r}
Accidents$Injury <- factor(Accidents$Injury)
set.seed(234)
df1 <- data.frame(Accidents)
index <- sample(1:nrow(Accidents), size=0.6*nrow(Accidents))
train_split <- df1[index,]
valid_split <- df1[-index,]


```

From the data codes sheet, we can infer that 
HOUR_I_R, 
ALCOHOL_I,
WKDY_I_R,
LGTCON_I_R, 
MAN_COL_I, 
SPD_LIM, 
VEH_INVL 
can be the predictors that can be
included in the analysis when no other information is provided like location and
weather conditions.

```{r}
modelNB2 <- naiveBayes(Injury ~ HOUR_I_R + ALCHL_I + WKDY_I_R + LGTCON_I_R +
MANCOL_I_R + SPD_LIM + VEH_INVL, data = train_split)


```

```{r}
model_pred <- predict(modelNB2, valid_split)
#confusionMatrix
table(model_pred,valid_split$Injury)
```

iii) Error rate = 7904/(16874)*100 = 46.8412

iv) There is no improvement

v) Naive Bayes assumes that a new record with that
category of predictor with no record has zero probability. Hence, we get a probability of zero.


